{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanmay/anaconda3/lib/python3.7/site-packages/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import autoencoder_conv2d\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from clusteringlayer import ClusteringLayer\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "from sklearn.utils.linear_assignment_ import linear_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x = np.concatenate((x_train, x_test))\n",
    "y = np.concatenate((y_train, y_test))\n",
    "x = x.reshape(x.shape + (1,))\n",
    "x = np.divide(x, 255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder, encoder = autoencoder_conv2d.autoencoderConv2D_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"AE\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 14, 14, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 7, 7, 64)          51264     \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "embedding (Dense)            (None, 10)                11530     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1152)              12672     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "deconv3 (Conv2DTranspose)    (None, 7, 7, 64)          73792     \n",
      "_________________________________________________________________\n",
      "deconv2 (Conv2DTranspose)    (None, 14, 14, 32)        51232     \n",
      "_________________________________________________________________\n",
      "deconv1 (Conv2DTranspose)    (None, 28, 28, 1)         801       \n",
      "=================================================================\n",
      "Total params: 275,979\n",
      "Trainable params: 275,979\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_epochs = 20\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer = 'adadelta', loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "274/274 - 8s - loss: 0.1122\n",
      "Epoch 2/20\n",
      "274/274 - 2s - loss: 0.1120\n",
      "Epoch 3/20\n",
      "274/274 - 2s - loss: 0.1118\n",
      "Epoch 4/20\n",
      "274/274 - 2s - loss: 0.1115\n",
      "Epoch 5/20\n",
      "274/274 - 2s - loss: 0.1113\n",
      "Epoch 6/20\n",
      "274/274 - 2s - loss: 0.1110\n",
      "Epoch 7/20\n",
      "274/274 - 2s - loss: 0.1107\n",
      "Epoch 8/20\n",
      "274/274 - 2s - loss: 0.1103\n",
      "Epoch 9/20\n",
      "274/274 - 2s - loss: 0.1100\n",
      "Epoch 10/20\n",
      "274/274 - 2s - loss: 0.1096\n",
      "Epoch 11/20\n",
      "274/274 - 2s - loss: 0.1093\n",
      "Epoch 12/20\n",
      "274/274 - 2s - loss: 0.1089\n",
      "Epoch 13/20\n",
      "274/274 - 2s - loss: 0.1085\n",
      "Epoch 14/20\n",
      "274/274 - 2s - loss: 0.1080\n",
      "Epoch 15/20\n",
      "274/274 - 2s - loss: 0.1076\n",
      "Epoch 16/20\n",
      "274/274 - 2s - loss: 0.1072\n",
      "Epoch 17/20\n",
      "274/274 - 2s - loss: 0.1067\n",
      "Epoch 18/20\n",
      "274/274 - 2s - loss: 0.1062\n",
      "Epoch 19/20\n",
      "274/274 - 3s - loss: 0.1057\n",
      "Epoch 20/20\n",
      "274/274 - 3s - loss: 0.1052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f331346e210>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x, x, batch_size = batch_size, epochs = pretrain_epochs, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add clustering layer\n",
    "\n",
    "clustering_layer = ClusteringLayer(10, name = 'clustering')(encoder.output)\n",
    "model = tf.keras.models.Model(inputs = encoder.input, outputs = clustering_layer)\n",
    "model.compile(optimizer = 'adam', loss = 'kld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize cluster centers using k-means\n",
    "\n",
    "kmeans = KMeans(n_clusters = 10, n_init = 20)\n",
    "y_pred = kmeans.fit_predict(encoder.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_last = np.copy(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_layer(name = 'clustering').set_weights([kmeans.cluster_centers_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute p_i by first raising q_i to the second power and then normalizing by frequency per cluster\n",
    "\n",
    "# computing an auxiliary target distribution\n",
    "def target_distribution(q):\n",
    "    weight = q ** 2 / q.sum(0)\n",
    "    return (weight.T / weight.sum(1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0\n",
    "index = 0\n",
    "tol = 0.001\n",
    "maxiter = 6000\n",
    "update_interval = 140\n",
    "index_array = np.arange(x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: acc = 0.09041, nmi = 0.22625, ari = 0.14565  ; loss= 0\n",
      "Iter 140: acc = 0.10210, nmi = 0.22079, ari = 0.15251  ; loss= 0.0\n",
      "Iter 280: acc = 0.10729, nmi = 0.22395, ari = 0.15452  ; loss= 0.0\n",
      "Iter 420: acc = 0.11540, nmi = 0.22360, ari = 0.15556  ; loss= 0.0\n",
      "Iter 560: acc = 0.11824, nmi = 0.21927, ari = 0.15217  ; loss= 0.0\n",
      "Iter 700: acc = 0.11936, nmi = 0.21654, ari = 0.15150  ; loss= 1e-05\n",
      "Iter 840: acc = 0.11607, nmi = 0.21404, ari = 0.15021  ; loss= 2e-05\n",
      "Iter 980: acc = 0.11243, nmi = 0.21165, ari = 0.14804  ; loss= 0.00013\n",
      "Iter 1120: acc = 0.10939, nmi = 0.21396, ari = 0.14824  ; loss= 0.0024\n",
      "Iter 1260: acc = 0.11291, nmi = 0.22853, ari = 0.15880  ; loss= 0.01724\n",
      "Iter 1400: acc = 0.12041, nmi = 0.25463, ari = 0.17783  ; loss= 0.07495\n",
      "Iter 1540: acc = 0.11950, nmi = 0.27923, ari = 0.19862  ; loss= 0.15616\n",
      "Iter 1680: acc = 0.11923, nmi = 0.30303, ari = 0.21987  ; loss= 0.19535\n",
      "Iter 1820: acc = 0.11584, nmi = 0.32115, ari = 0.23239  ; loss= 0.21453\n",
      "Iter 1960: acc = 0.11374, nmi = 0.33204, ari = 0.23913  ; loss= 0.21427\n",
      "Iter 2100: acc = 0.11441, nmi = 0.34384, ari = 0.24844  ; loss= 0.22642\n",
      "Iter 2240: acc = 0.11180, nmi = 0.34900, ari = 0.25216  ; loss= 0.23489\n",
      "Iter 2380: acc = 0.11056, nmi = 0.35589, ari = 0.25856  ; loss= 0.21937\n",
      "Iter 2520: acc = 0.10979, nmi = 0.36438, ari = 0.26473  ; loss= 0.22559\n",
      "Iter 2660: acc = 0.11216, nmi = 0.36832, ari = 0.26721  ; loss= 0.21552\n",
      "Iter 2800: acc = 0.10921, nmi = 0.37227, ari = 0.26969  ; loss= 0.21318\n",
      "Iter 2940: acc = 0.11063, nmi = 0.37471, ari = 0.27172  ; loss= 0.20309\n",
      "Iter 3080: acc = 0.11066, nmi = 0.37839, ari = 0.27443  ; loss= 0.1935\n",
      "Iter 3220: acc = 0.11120, nmi = 0.38320, ari = 0.27829  ; loss= 0.18833\n",
      "Iter 3360: acc = 0.10989, nmi = 0.38732, ari = 0.28117  ; loss= 0.18913\n",
      "Iter 3500: acc = 0.10924, nmi = 0.39002, ari = 0.28360  ; loss= 0.18477\n",
      "Iter 3640: acc = 0.10886, nmi = 0.39281, ari = 0.28529  ; loss= 0.17401\n",
      "Iter 3780: acc = 0.10873, nmi = 0.39306, ari = 0.28503  ; loss= 0.1862\n",
      "Iter 3920: acc = 0.10704, nmi = 0.39551, ari = 0.28674  ; loss= 0.17858\n",
      "Iter 4060: acc = 0.10807, nmi = 0.39631, ari = 0.28710  ; loss= 0.17507\n",
      "Iter 4200: acc = 0.10790, nmi = 0.39886, ari = 0.28972  ; loss= 0.17418\n",
      "Iter 4340: acc = 0.10810, nmi = 0.40007, ari = 0.29018  ; loss= 0.17114\n",
      "Iter 4480: acc = 0.10846, nmi = 0.40140, ari = 0.29175  ; loss= 0.15747\n",
      "Iter 4620: acc = 0.10857, nmi = 0.40163, ari = 0.29168  ; loss= 0.16058\n",
      "Iter 4760: acc = 0.10774, nmi = 0.40437, ari = 0.29431  ; loss= 0.14646\n",
      "Iter 4900: acc = 0.10799, nmi = 0.40521, ari = 0.29455  ; loss= 0.15211\n",
      "Iter 5040: acc = 0.10741, nmi = 0.40550, ari = 0.29527  ; loss= 0.13699\n",
      "Iter 5180: acc = 0.10780, nmi = 0.40658, ari = 0.29552  ; loss= 0.15346\n",
      "Iter 5320: acc = 0.10841, nmi = 0.40627, ari = 0.29573  ; loss= 0.15939\n",
      "Iter 5460: acc = 0.10834, nmi = 0.40626, ari = 0.29566  ; loss= 0.14087\n",
      "Iter 5600: acc = 0.10893, nmi = 0.40574, ari = 0.29459  ; loss= 0.16268\n",
      "Iter 5740: acc = 0.10896, nmi = 0.40569, ari = 0.29501  ; loss= 0.13424\n",
      "Iter 5880: acc = 0.10923, nmi = 0.40634, ari = 0.29536  ; loss= 0.13564\n"
     ]
    }
   ],
   "source": [
    "for ite in range(int(maxiter)):\n",
    "    if ite % update_interval == 0:\n",
    "        q = model.predict(x, verbose = 0)\n",
    "        p = target_distribution(q)  # update the auxiliary target distribution p\n",
    "\n",
    "        # evaluate the clustering performance\n",
    "        y_pred = q.argmax(1)\n",
    "        if y is not None:\n",
    "            acc = np.round(metrics.accuracy_score(y, y_pred), 5)\n",
    "            nmi = np.round(metrics.normalized_mutual_info_score(y, y_pred), 5)\n",
    "            ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)\n",
    "            loss = np.round(loss, 5)\n",
    "            print('Iter %d: acc = %.5f, nmi = %.5f, ari = %.5f' % (ite, acc, nmi, ari), ' ; loss=', loss)\n",
    "\n",
    "        # check stop criterion - model convergence\n",
    "        delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "        y_pred_last = np.copy(y_pred)\n",
    "        if ite > 0 and delta_label < tol:\n",
    "            print('delta_label ', delta_label, '< tol ', tol)\n",
    "            print('Reached tolerance threshold. Stopping training.')\n",
    "            break\n",
    "    idx = index_array[index * batch_size: min((index+1) * batch_size, x.shape[0])]\n",
    "    loss = model.train_on_batch(x = x[idx], y = p[idx])\n",
    "    index = index + 1 if (index + 1) * batch_size <= x.shape[0] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
